{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d5fe7b-c4d6-47f3-bf68-022ad64dfa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files from dataset.zip have been extracted to dataset_extracted\n",
      "Files from logs.zip have been extracted to logs_extracted\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# List of zip files to unzip\n",
    "zip_files = [\"dataset.zip\", \"logs.zip\"]\n",
    "\n",
    "# Loop through each zip file and extract\n",
    "for zip_file in zip_files:\n",
    "    extract_dir = zip_file.replace(\".zip\", \"_extracted\")  # Create a folder based on the zip file name\n",
    "    os.makedirs(extract_dir, exist_ok=True)  # Ensure the folder exists\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)  # Extract contents\n",
    "    print(f\"Files from {zip_file} have been extracted to {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2dd12fa-e834-4902-8940-ee93613905ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (24.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (75.5.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.5.0\n",
      "    Uninstalling setuptools-75.5.0:\n",
      "      Successfully uninstalled setuptools-75.5.0\n",
      "Successfully installed setuptools-75.6.0 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf7c925-12c1-4f4f-9ea0-c25451f0e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.0rc1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (1.14.1)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (11.0.0)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.25.0rc1-cp313-cp313-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.9 MB 17.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.9 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.36.1 lazy-loader-0.4 scikit-image-0.25.0rc1 tifffile-2024.9.20\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image --only-binary :all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef09487-d22a-4b61-a7d5-37d18c1a3399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.25.0rc1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (11.0.0)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (4.6.2.post1)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.1-cp313-abi3-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.5.1 (from gradio)\n",
      "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.12-cp313-none-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (24.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.8.2-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typing-extensions~=4.0 (from gradio)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from gradio-client==1.5.1->gradio)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.1->gradio)\n",
      "  Downloading websockets-14.1-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.25.1->gradio)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.25.1->gradio)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.27.1-cp313-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thanush naidu\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
      "   ---------------------------------------- 0.0/57.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.6/57.2 MB 12.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.5/57.2 MB 10.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 7.1/57.2 MB 11.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 9.7/57.2 MB 11.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 12.6/57.2 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 14.9/57.2 MB 11.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 16.8/57.2 MB 11.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 18.1/57.2 MB 10.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 21.5/57.2 MB 11.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 24.1/57.2 MB 11.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 27.0/57.2 MB 11.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 29.9/57.2 MB 12.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 32.8/57.2 MB 12.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 36.4/57.2 MB 12.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 38.5/57.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 41.7/57.2 MB 12.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 44.8/57.2 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 49.0/57.2 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 52.7/57.2 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 54.8/57.2 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  57.1/57.2 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 57.2/57.2 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/38.8 MB 15.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.0/38.8 MB 12.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 7.9/38.8 MB 12.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 10.7/38.8 MB 13.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.2/38.8 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 17.6/38.8 MB 14.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.2/38.8 MB 14.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.6/38.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.6/38.8 MB 15.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.7/38.8 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.9/38.8 MB 14.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.2/38.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.1-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Downloading orjson-3.10.12-cp313-none-win_amd64.whl (134 kB)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 16.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.5 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 13.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp313-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.5 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.8.2-py3-none-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.1/9.6 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.5/9.6 MB 13.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.9/9.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading websockets-14.1-cp313-cp313-win_amd64.whl (163 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: markupsafe\n",
      "  Building wheel for markupsafe (setup.py): started\n",
      "  Building wheel for markupsafe (setup.py): finished with status 'done'\n",
      "  Created wheel for markupsafe: filename=MarkupSafe-2.1.5-py3-none-any.whl size=9911 sha256=ab2211988c9ee50deda605fd3b0ff695bfab30c08c8ebba69ee0126c72e7a3d1\n",
      "  Stored in directory: c:\\users\\thanush naidu\\appdata\\local\\pip\\cache\\wheels\\c2\\0c\\c0\\d6d953ac80cacc2dd1d329d675c67d1e7775bad02a8faedef0\n",
      "Successfully built markupsafe\n",
      "Installing collected packages: pytz, pydub, websockets, tzdata, typing-extensions, tqdm, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, opencv-python-headless, mdurl, markupsafe, fsspec, filelock, ffmpy, click, audioop-lts, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, pandas, markdown-it-py, huggingface-hub, safehttpx, rich, pydantic, gradio-client, typer, fastapi, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 audioop-lts-0.2.1 click-8.1.7 fastapi-0.115.6 ffmpy-0.4.0 filelock-3.16.1 fsspec-2024.10.0 gradio-5.8.0 gradio-client-1.5.1 huggingface-hub-0.26.5 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 opencv-python-headless-4.10.0.84 orjson-3.10.12 pandas-2.2.3 pydantic-2.10.3 pydantic-core-2.27.1 pydub-0.25.1 python-multipart-0.0.19 pytz-2024.2 rich-13.9.4 ruff-0.8.2 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.3 tomlkit-0.13.2 tqdm-4.67.1 typer-0.15.1 typing-extensions-4.12.2 tzdata-2024.2 uvicorn-0.32.1 websockets-14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio opencv-python-headless numpy scipy scikit-image matplotlib pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45ccf71-d15d-4cfd-9ff1-8ce695beba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import spectrogram, stft, windows\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f1cd24-9add-4762-8d79-0282e8dfa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize and pad function\n",
    "def resize_and_pad(image, target_size=(256, 256), pad_color=0):\n",
    "    height, width = image.shape[:2]\n",
    "    target_width, target_height = target_size\n",
    "    scaling_factor = min(target_width / width, target_height / height)\n",
    "    new_width = int(scaling_factor * width)\n",
    "    new_height = int(scaling_factor * height)\n",
    "    resized = cv.resize(image, (new_width, new_height), interpolation=cv.INTER_AREA)\n",
    "    top_pad = (target_height - new_height) // 2\n",
    "    bottom_pad = target_height - new_height - top_pad\n",
    "    left_pad = (target_width - new_width) // 2\n",
    "    right_pad = target_width - new_width - left_pad\n",
    "    padded = cv.copyMakeBorder(resized, top_pad, bottom_pad, left_pad, right_pad, cv.BORDER_CONSTANT, value=pad_color)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39cde5c-108f-4fbe-a522-ea8a307bdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image Preprocessing script, no need to run this in real time\n",
    "\n",
    "# def preprocess_images(input_folder, output_folder, size):\n",
    "#     \"\"\"\n",
    "#     Preprocess images by converting them to grayscale, resizing and padding.\n",
    "\n",
    "#     Args:\n",
    "#         input_folder (str): Orginal dataset folder.\n",
    "#         output_folder (str): Path for saving the preprocessed images.\n",
    "#         size (tuple): New Target size for resized images.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "    \n",
    "#     for root, dirs, files in os.walk(input_folder):\n",
    "\n",
    "#         relative_path = os.path.relpath(root, input_folder)\n",
    "#         output_subfolder = os.path.join(output_folder, relative_path)\n",
    "\n",
    "#         if not os.path.exists(output_subfolder):\n",
    "#             os.makedirs(output_subfolder)\n",
    "\n",
    "#         for file_name in files:\n",
    "#             if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "\n",
    "#                 file_path = os.path.join(root, file_name)\n",
    "#                 img = cv.imread(file_path)\n",
    "\n",
    "#                 if img is None:\n",
    "#                     print(f\"Error loading image: {file_path}\")\n",
    "#                     continue\n",
    "\n",
    "#                 resized = resize_and_pad(img, target_size=size) ## resizing all images to standard size of 256x256\n",
    "#                 gray = cv.cvtColor(resized, cv.COLOR_BGR2GRAY)\n",
    "                \n",
    "\n",
    "#                 output_path = os.path.join(output_subfolder, file_name)\n",
    "#                 cv.imwrite(output_path, gray)\n",
    "\n",
    "#                 print(f\"Processed: {file_path} -> {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dde74bd-b2cf-450a-81e6-823e9c4d75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 2D STFT spectrogram\n",
    "def compute_spectrogram(image, window_size=32, overlap=0.5, window_type=\"hann\"):\n",
    "    image = image / 255.0  # Normalize\n",
    "    step = int(window_size * (1 - overlap))\n",
    "    rows, cols = image.shape\n",
    "    aggregated_magnitude = np.zeros((rows, cols))\n",
    "    weights = np.zeros_like(aggregated_magnitude)\n",
    "    if window_type == \"hann\":\n",
    "        window = windows.hann(window_size)\n",
    "    elif window_type == \"gaussian\":\n",
    "        window = windows.gaussian(window_size, std=window_size / 6)\n",
    "    elif window_type == \"boxcar\":\n",
    "        window = windows.boxcar(window_size)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported window type\")\n",
    "    window_2d = np.outer(window, window)\n",
    "    for i in range(0, rows - window_size + 1, step):\n",
    "        for j in range(0, cols - window_size + 1, step):\n",
    "            region = image[i : i + window_size, j : j + window_size]\n",
    "            region_windowed = region * window_2d\n",
    "            region_fft = np.fft.fft2(region_windowed)\n",
    "            region_magnitude = np.abs(np.fft.fftshift(region_fft))\n",
    "            aggregated_magnitude[i : i + window_size, j : j + window_size] += region_magnitude\n",
    "            weights[i : i + window_size, j : j + window_size] += window_2d\n",
    "    aggregated_magnitude /= np.maximum(weights, 1e-8)\n",
    "    return aggregated_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd8c60f-a334-428b-94ab-c5fde154974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match spectrograms\n",
    "def match_spectrograms(s1, s2, method=\"pearson\"):\n",
    "    s1 = s1 / np.max(s1)\n",
    "    s2 = s2 / np.max(s2)\n",
    "    if method == \"ssim\":\n",
    "        correlation = ssim(s1, s2, data_range=1.0)\n",
    "    elif method == \"pearson\":\n",
    "        correlation = np.corrcoef(s1.flatten(), s2.flatten())[0, 1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method\")\n",
    "    return round(correlation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef39edd1-48da-441d-a1b5-6efbd992b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display image and spectrogram\n",
    "def generate_spectrogram_image(image, title=\"Spectrogram\"):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(np.log(1 + image), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    buffer = BytesIO()\n",
    "    plt.savefig(buffer, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    buffer.seek(0)\n",
    "    plt.close()\n",
    "    return Image.open(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8ded0a-a9f8-40bc-b42b-fca413ef3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Gradio Functionality\n",
    "def frequency_matching(target_image_path, dataset_folder, top_n=3):\n",
    "    target_image = cv.imread(target_image_path, cv.IMREAD_GRAYSCALE)\n",
    "    if target_image is None:\n",
    "        raise ValueError(\"Could not load target image\")\n",
    "    target_image_resized = resize_and_pad(target_image, target_size=(256, 256))\n",
    "    target_spectrogram = compute_spectrogram(target_image_resized)\n",
    "\n",
    "    results = []\n",
    "    for root, _, files in os.walk(dataset_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                dataset_image = cv.imread(file_path, cv.IMREAD_GRAYSCALE)\n",
    "                if dataset_image is None:\n",
    "                    continue\n",
    "                dataset_image_resized = resize_and_pad(dataset_image, target_size=(256, 256))\n",
    "                dataset_spectrogram = compute_spectrogram(dataset_image_resized)\n",
    "                correlation = match_spectrograms(target_spectrogram, dataset_spectrogram)\n",
    "                results.append((file_path, correlation))\n",
    "\n",
    "    \n",
    "\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Prepare outputs\n",
    "    spectrogram_image = generate_spectrogram_image(target_spectrogram, \"Target Spectrogram\")\n",
    "    matches = [(res[0], generate_spectrogram_image(compute_spectrogram(cv.imread(res[0], cv.IMREAD_GRAYSCALE)), f\"Match {i+1}\"), res[1]) for i, res in enumerate(results)]\n",
    "    return spectrogram_image, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4b21f9-924e-479d-9782-d8623cbaff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matches(target_image, top_n):\n",
    "    \"\"\"\n",
    "    Processes the target image, matches it against the dataset, and returns results.\n",
    "\n",
    "    Args:\n",
    "        target_image (str): Path to the target image.\n",
    "        top_n (int): Number of top matches to return.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Target spectrogram image and a list of match images with captions.\n",
    "    \"\"\"\n",
    "    dataset_folder = \"./dataset/preprocessed_data/natural_images\"\n",
    "    spectrogram_image = generate_spectrogram_image(\n",
    "        compute_spectrogram(cv.imread(target_image, cv.IMREAD_GRAYSCALE)),\n",
    "        title=\"Target Spectrogram\"\n",
    "    )\n",
    "\n",
    "    # Perform matching\n",
    "    _, matches = frequency_matching(target_image, dataset_folder, top_n)\n",
    "    \n",
    "    results = []\n",
    "    for match in matches:\n",
    "        match_image = cv.imread(match[0], cv.IMREAD_COLOR)\n",
    "        match_image = cv.cvtColor(match_image, cv.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "        match_image = Image.fromarray(match_image)\n",
    "        \n",
    "        match_spectrogram = generate_spectrogram_image(\n",
    "            compute_spectrogram(cv.imread(match[0], cv.IMREAD_GRAYSCALE)),\n",
    "            title=\"Match Spectrogram\"\n",
    "        )\n",
    "\n",
    "        # Concatenate match image and spectrogram horizontally\n",
    "        combined_image = Image.new(\"RGB\", (match_image.width + match_spectrogram.width, match_image.height))\n",
    "        combined_image.paste(match_image, (0, 0))\n",
    "        combined_image.paste(match_spectrogram, (match_image.width, 0))\n",
    "\n",
    "        # Add combined image and caption to results\n",
    "        caption = f\"Correlation: {match[2]}\"\n",
    "        results.append((combined_image, caption))\n",
    "\n",
    "    return spectrogram_image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89187f7b-0ce9-4e00-ba2a-b2ea8e0de18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\blocks.py\", line 2043, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\blocks.py\", line 1590, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Temp\\ipykernel_23816\\1619767398.py\", line 14, in display_matches\n",
      "    compute_spectrogram(cv.imread(target_image, cv.IMREAD_GRAYSCALE)),\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\thanush naidu\\AppData\\Local\\Temp\\ipykernel_23816\\4026205578.py\", line 3, in compute_spectrogram\n",
      "    image = image / 255.0  # Normalize\n",
      "            ~~~~~~^~~~~~~\n",
      "TypeError: unsupported operand type(s) for /: 'NoneType' and 'float'\n"
     ]
    }
   ],
   "source": [
    "input_image = gr.Image(label=\"Upload Target Image\", type=\"filepath\")\n",
    "num_matches = gr.Slider(minimum=1, maximum=10, value=3, step=1, label=\"Number of Matches\")\n",
    "spectrogram_output = gr.Image(label=\"Target Spectrogram\")\n",
    "matches_output = gr.Gallery(label=\"Top Matches (Image + Spectrogram + Correlation)\")\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=display_matches,\n",
    "    inputs=[input_image, num_matches],\n",
    "    outputs=[spectrogram_output, matches_output],\n",
    "    title=\"Frequency Matching Tool\",\n",
    "    description=\"Upload an image to find spectrogram matches.\",\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b65686-1c6d-4930-af74-dfcb4da3bccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
